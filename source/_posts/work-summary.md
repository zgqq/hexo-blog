---
title: work-summary
date: 2017-03-04 10:47:16
tags:
---

# 第一天
## 打开电脑
今天第一天上班，给我配了一台华硕pc，妈的，一打开，mdzz，一个附带360的win7，我就看看了周围什么情况，清一色的Windows，我准备感叹一声，突然间，一个大佬拿了一台macbook出现在我眼前，有一种出淤泥而不染的感觉，吓得我邪恶地拿起了我的U盘，开始准备填坑之路
## 准备折腾
 因为刚进去，我也不敢随便把win7删掉，等下要填表什么的就炸了，结果发现分区表不是gpt，我还真的不会装了，提心吊胆地把分区表改成gpt，突然眼前一蓝，开始第二次出击，没想到的意思，我正走向一个天大的暗坑，由于我一时心切，安装archlinux的时候，没怎么看文档，系统怎么装都启动不了，装了很多次，我真的有点绝望，关键在公司估计很难找到会搞这玩意的人，没办法，硬着头皮搞，突然在biOS界面发现一个选项，fuck，对，只有window系统能够uefi启动，华硕认ms做爹了？
修改选项后，接下来系统就可以启动了，安装de又是一坑，startx启动不了，估计是没安装xinit-sessions这个包。又是一阵子折腾，还有要记住不要太快改语言，不然等下报错都是方块，更加蛋疼，但是一波未平一波又起，如果没有设置语言为utf8，tmux就会报错，哎，今天真的被虐了，虽然我被archlinux虐了很多次
## 明天
明天还有问题，第一就是要翻墙，第二就是解决证书问题(估计是时间设置)
# 第二天
## 需求
老大给了我一个任务，分析两个2G的日志文件，要求就是找出某一个时间段，访问次数最多的url，和找出最消耗流量的url，其实听起来不难，做起来还是挺难的，shell命令可以搞定简单的统计，但是某个时间应该是有点难吧，因为时间那个字段看起来不是那么规则，我想到用python来处理，觉得python的性能一般，我也不是很熟，最后用了java了
## 解析日志工具
我还加了一个feature，可以分析多个日志大文件，实现原理相当简单，比如要取出前30条记录，先分析第一个日志文件，然后去前30条记录，强行释放内存后，分析第二个文件，以此类推
## 有坑
写的过程中，也碰到了几个吭
* SimpleFormatDate.parse有坑，这里注意要记住本地化问题，比如本地环境是zh_CN，是无法解析1/Mar/2017之类的日期，要调用parse(str,locale)这个方法
* 第二次个坑就是ArrayList.subList，他会返回一个内部类，包含了主类的引用，无法释放内存
* 第三个坑就是int类型溢出，统计response size 的时候，记录太大，用int容易溢出，造成结果无法理解

# 第三天
修复很多环境问题，启动就是fasd无法记录进过的目录，这个问题容易解决，zshrc加入fasd插件，fzf快捷键无法使用，执行一下~/.fzf/install就行了。virtualbox镜像启动不了，可能是镜像不完整，用idea项目结构有时候会很奇怪，直接把项目下.idea目录给删了就行，idea还有一个神级posfix，就是lambda，很好的辅助完成哦
